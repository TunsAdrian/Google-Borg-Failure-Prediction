{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:14:28.825983600Z",
     "start_time": "2023-06-17T13:14:24.673541300Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "dataset_root_path = \"D:\\\\Documents\\\\Programming\\\\Python-Projects\\\\Clusterdata_2019_e\\\\\"\n",
    "spark = SparkSession.builder.appName('Failure Prediction on Google Borg Cluster Traces').master('local[*]').getOrCreate()\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '3g')\n",
    "SparkContext.setSystemProperty('spark.driver.memory', '3g')\n",
    "\n",
    "jobs_train_df = spark.read.parquet(\"./training_data/jobs_data.parquet\")\n",
    "jobs_test_df = spark.read.parquet(\"./test_data/jobs_data.parquet\")\n",
    "\n",
    "tasks_train_df = spark.read.parquet(\"./training_data/tasks_data.parquet\")\n",
    "tasks_test_df = spark.read.parquet(\"./test_data/tasks_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- scheduling_class: long (nullable = true)\n",
      " |-- priority: long (nullable = true)\n",
      " |-- cpus: double (nullable = true)\n",
      " |-- memory: double (nullable = true)\n",
      " |-- event_success: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- scheduling_class: long (nullable = true)\n",
      " |-- priority: long (nullable = true)\n",
      " |-- cpus: double (nullable = true)\n",
      " |-- memory: double (nullable = true)\n",
      " |-- event_success: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- scheduling_class: long (nullable = true)\n",
      " |-- priority: long (nullable = true)\n",
      " |-- cpus: double (nullable = true)\n",
      " |-- memory: double (nullable = true)\n",
      " |-- event_success: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- scheduling_class: long (nullable = true)\n",
      " |-- priority: long (nullable = true)\n",
      " |-- cpus: double (nullable = true)\n",
      " |-- memory: double (nullable = true)\n",
      " |-- event_success: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jobs_train_df.printSchema()\n",
    "jobs_test_df.printSchema()\n",
    "tasks_train_df.printSchema()\n",
    "tasks_test_df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T12:54:15.979947600Z",
     "start_time": "2023-06-17T12:54:15.917143700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job train dataset count: 1087936\n",
      "Job test dataset count: 313905\n",
      "Task train dataset count: 27976115\n",
      "Task test dataset count: 89928090\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, LogisticRegression\n",
    "\n",
    "# TODO: check if pipeline stages are actually needed\n",
    "stages = []\n",
    "\n",
    "assemblerInputs = [\"scheduling_class\", \"priority\", \"cpus\", \"memory\"]\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "\n",
    "jobs_train_data = pipeline.fit(jobs_train_df).transform(jobs_train_df)\n",
    "jobs_test_data = pipeline.fit(jobs_test_df).transform(jobs_test_df)\n",
    "\n",
    "print('Job train dataset count:', jobs_train_data.count())\n",
    "print('Job test dataset count:', jobs_test_data.count())\n",
    "\n",
    "\n",
    "tasks_train_data = pipeline.fit(tasks_train_df).transform(tasks_train_df)\n",
    "tasks_test_data = pipeline.fit(tasks_test_df).transform(tasks_test_df)\n",
    "\n",
    "print('Task train dataset count:', tasks_train_data.count())\n",
    "print('Task test dataset count:', tasks_test_data.count())\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(labelCol=\"event_success\")\n",
    "random_forest = RandomForestClassifier(labelCol='event_success')\n",
    "gradient_boosting = GBTClassifier(labelCol='event_success')\n",
    "logistic_regression = LogisticRegression(labelCol='event_success')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:14:30.268847200Z",
     "start_time": "2023-06-17T13:14:28.825983600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Jobs Failure Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dt_model_jobs = decision_tree.fit(jobs_train_data)\n",
    "dt_prediction_jobs = dt_model_jobs.transform(jobs_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T12:56:27.233922400Z",
     "start_time": "2023-06-17T12:56:24.393824900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.821560663257992\n",
      "F1 score: 0.8223131325062677\n",
      "Recall: 0.7430237631089193\n",
      "Feature 'scheduling_class': 0.50\n",
      "Feature 'priority': 0.44\n",
      "Feature 'cpus': 0.01\n",
      "Feature 'memory': 0.04\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"Accuracy:\", evaluator.evaluate(dt_prediction_jobs))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "print(\"F1 score:\", evaluator.evaluate(dt_prediction_jobs))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "print(\"Recall:\", evaluator.evaluate(dt_prediction_jobs))\n",
    "\n",
    "\n",
    "# Evaluate feature importance\n",
    "feature_importance = dt_model_jobs.featureImportances.toArray()\n",
    "\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f\"Feature '{column}': {feature_importance[i]:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T12:56:29.695675600Z",
     "start_time": "2023-06-17T12:56:28.874056100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "rf_model_jobs = random_forest.fit(jobs_train_data)\n",
    "rf_prediction_jobs = dt_model_jobs.transform(jobs_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T12:57:59.113733Z",
     "start_time": "2023-06-17T12:57:56.423683700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.821560663257992\n",
      "F1 score: 0.8223131325062677\n",
      "Recall: 0.7430237631089193\n",
      "Feature 'scheduling_class': 0.56\n",
      "Feature 'priority': 0.26\n",
      "Feature 'cpus': 0.07\n",
      "Feature 'memory': 0.11\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"Accuracy:\", evaluator.evaluate(rf_prediction_jobs))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "print(\"F1 score:\", evaluator.evaluate(rf_prediction_jobs))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "print(\"Recall:\", evaluator.evaluate(rf_prediction_jobs))\n",
    "\n",
    "\n",
    "# Evaluate feature importance\n",
    "feature_importance = rf_model_jobs.featureImportances.toArray()\n",
    "\n",
    "# Show feature importance\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f\"Feature '{column}': {feature_importance[i]:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T12:58:03.723796200Z",
     "start_time": "2023-06-17T12:58:03.133816700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "gb_model_jobs = gradient_boosting.fit(jobs_train_data)\n",
    "gb_prediction_jobs = gb_model_jobs.transform(jobs_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T12:58:23.396337900Z",
     "start_time": "2023-06-17T12:58:07.624094300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8352527038435196\n",
      "F1 score: 0.8359601469413815\n",
      "Recall: 0.7557088342657072\n",
      "Feature 'scheduling_class': 0.42\n",
      "Feature 'priority': 0.37\n",
      "Feature 'cpus': 0.10\n",
      "Feature 'memory': 0.11\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"Accuracy:\", evaluator.evaluate(gb_prediction_jobs))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "print(\"F1 score:\", evaluator.evaluate(gb_prediction_jobs))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "print(\"Recall:\", evaluator.evaluate(gb_prediction_jobs))\n",
    "\n",
    "\n",
    "# Evaluate feature importance\n",
    "feature_importance = gb_model_jobs.featureImportances.toArray()\n",
    "\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f\"Feature '{column}': {feature_importance[i]:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T12:58:30.278939600Z",
     "start_time": "2023-06-17T12:58:29.709090600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "lr_model_jobs = logistic_regression.fit(jobs_train_data)\n",
    "lr_prediction_jobs = lr_model_jobs.transform(jobs_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T12:58:35.723756400Z",
     "start_time": "2023-06-17T12:58:32.823751300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.623366942227744\n",
      "F1 score: 0.6253513097971465\n",
      "Recall: 0.5847889595149078\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"Accuracy:\", evaluator.evaluate(lr_prediction_jobs))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "print(\"F1 score:\", evaluator.evaluate(lr_prediction_jobs))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "print(\"Recall:\", evaluator.evaluate(lr_prediction_jobs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T12:58:37.504978700Z",
     "start_time": "2023-06-17T12:58:36.643833Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tasks Failure Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "dt_model_tasks = decision_tree.fit(tasks_train_data)\n",
    "dt_prediction_tasks = dt_model_tasks.transform(tasks_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:00:52.879057300Z",
     "start_time": "2023-06-17T12:59:55.508994400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "dt_model_tasks.save('./task_models_TML/decision_tree')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:02:49.138783700Z",
     "start_time": "2023-06-17T13:02:48.422642400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9870222863623591\n",
      "F1 score: 0.9876461588608803\n",
      "Recall: 0.9869271382743618\n",
      "Feature 'scheduling_class': 0.33\n",
      "Feature 'priority': 0.55\n",
      "Feature 'cpus': 0.08\n",
      "Feature 'memory': 0.04\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"Accuracy:\", evaluator.evaluate(dt_prediction_tasks))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "print(\"F1 score:\", evaluator.evaluate(dt_prediction_tasks))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "print(\"Recall:\", evaluator.evaluate(dt_prediction_tasks))\n",
    "\n",
    "\n",
    "# Evaluate feature importance\n",
    "feature_importance = dt_model_tasks.featureImportances.toArray()\n",
    "\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f\"Feature '{column}': {feature_importance[i]:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:08:01.942675800Z",
     "start_time": "2023-06-17T13:03:09.993985700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "rf_model_tasks = random_forest.fit(tasks_train_data)\n",
    "rf_prediction_tasks = rf_model_tasks.transform(tasks_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:19:26.803719300Z",
     "start_time": "2023-06-17T13:16:57.723553400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "rf_model_tasks.save('./task_models_TML/random_forest')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:19:27.873719Z",
     "start_time": "2023-06-17T13:19:26.803719300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9872281063680992\n",
      "F1 score: 0.9878044591466593\n",
      "Recall: 0.9874611452082195\n",
      "Feature 'scheduling_class': 0.36\n",
      "Feature 'priority': 0.44\n",
      "Feature 'cpus': 0.09\n",
      "Feature 'memory': 0.12\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"Accuracy:\", evaluator.evaluate(rf_prediction_tasks))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "print(\"F1 score:\", evaluator.evaluate(rf_prediction_tasks))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "print(\"Recall:\", evaluator.evaluate(rf_prediction_tasks))\n",
    "\n",
    "\n",
    "# Evaluate feature importance\n",
    "feature_importance = rf_model_tasks.featureImportances.toArray()\n",
    "\n",
    "# Show feature importance\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f\"Feature '{column}': {feature_importance[i]:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:26:28.465615400Z",
     "start_time": "2023-06-17T13:19:27.873719Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "gb_model_tasks = gradient_boosting.fit(tasks_train_data)\n",
    "gb_prediction_tasks = gb_model_tasks.transform(tasks_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:45:12.240474500Z",
     "start_time": "2023-06-17T13:26:28.465615400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "gb_model_tasks.save('./task_models_TML/gradient_boosting')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:45:12.941634800Z",
     "start_time": "2023-06-17T13:45:12.241475500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9893820829509444\n",
      "F1 score: 0.9898181903124817\n",
      "Recall: 0.9891720642087517\n",
      "Feature 'scheduling_class': 0.32\n",
      "Feature 'priority': 0.56\n",
      "Feature 'cpus': 0.06\n",
      "Feature 'memory': 0.07\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"Accuracy:\", evaluator.evaluate(gb_prediction_tasks))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "print(\"F1 score:\", evaluator.evaluate(gb_prediction_tasks))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "print(\"Recall:\", evaluator.evaluate(gb_prediction_tasks))\n",
    "\n",
    "\n",
    "# Evaluate feature importance\n",
    "feature_importance = gb_model_tasks.featureImportances.toArray()\n",
    "\n",
    "# Show feature importance\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f\"Feature '{column}': {feature_importance[i]:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:51:02.202566100Z",
     "start_time": "2023-06-17T13:45:12.942634600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "lr_model_tasks = logistic_regression.fit(tasks_train_data)\n",
    "lr_prediction_tasks = lr_model_tasks.transform(tasks_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:55:22.095273500Z",
     "start_time": "2023-06-17T13:51:02.203566Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "lr_model_tasks.save('./task_models_TML/logistic_regression')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T13:55:22.205334100Z",
     "start_time": "2023-06-17T13:55:22.109223400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9066080020158329\n",
      "F1 score: 0.9256697714562917\n",
      "Recall: 0.904947786034295\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"Accuracy:\", evaluator.evaluate(lr_prediction_tasks))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "print(\"F1 score:\", evaluator.evaluate(lr_prediction_tasks))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "print(\"Recall:\", evaluator.evaluate(lr_prediction_tasks))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:02:10.514935200Z",
     "start_time": "2023-06-17T13:55:22.205334100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
