{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-25T21:29:12.949445600Z",
     "start_time": "2023-06-25T21:29:08.869351900Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "dataset_root_path = \"D:\\\\Documents\\\\Programming\\\\Python-Projects\\\\Clusterdata_2019_e\\\\\"\n",
    "spark = SparkSession.builder.appName('Failure Prediction on Google Borg Cluster Traces').master('local[*]').getOrCreate()\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '3g')\n",
    "SparkContext.setSystemProperty('spark.driver.memory', '3g')\n",
    "\n",
    "jobs_train_df = spark.read.parquet(\"./training_data/jobs_data.parquet\")\n",
    "jobs_test_df = spark.read.parquet(\"./test_data/jobs_data.parquet\")\n",
    "\n",
    "tasks_train_df = spark.read.parquet(\"./training_data/tasks_data.parquet\")\n",
    "tasks_test_df = spark.read.parquet(\"./test_data/tasks_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- scheduling_class: long (nullable = true)\n",
      " |-- priority: long (nullable = true)\n",
      " |-- cpus: double (nullable = true)\n",
      " |-- memory: double (nullable = true)\n",
      " |-- event_success: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- scheduling_class: long (nullable = true)\n",
      " |-- priority: long (nullable = true)\n",
      " |-- cpus: double (nullable = true)\n",
      " |-- memory: double (nullable = true)\n",
      " |-- event_success: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- scheduling_class: long (nullable = true)\n",
      " |-- priority: long (nullable = true)\n",
      " |-- cpus: double (nullable = true)\n",
      " |-- memory: double (nullable = true)\n",
      " |-- event_success: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- scheduling_class: long (nullable = true)\n",
      " |-- priority: long (nullable = true)\n",
      " |-- cpus: double (nullable = true)\n",
      " |-- memory: double (nullable = true)\n",
      " |-- event_success: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jobs_train_df.printSchema()\n",
    "jobs_test_df.printSchema()\n",
    "tasks_train_df.printSchema()\n",
    "tasks_test_df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T18:21:18.551716200Z",
     "start_time": "2023-06-25T18:21:18.491685900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job train dataset count: 1087936\n",
      "Job test dataset count: 313905\n",
      "Task train dataset count: 27976115\n",
      "Task test dataset count: 89928090\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, LogisticRegression\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(inputCol=\"scheduling_class\", outputCol=\"scheduling_class_encoded\")\n",
    "assemblerInputs = [\"scheduling_class_encoded\", \"priority\", \"cpus\", \"memory\"]\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[one_hot_encoder, assembler])\n",
    "\n",
    "jobs_train_data = pipeline.fit(jobs_train_df).transform(jobs_train_df)\n",
    "jobs_test_data = pipeline.fit(jobs_test_df).transform(jobs_test_df)\n",
    "\n",
    "print('Job train dataset count:', jobs_train_data.count())\n",
    "print('Job test dataset count:', jobs_test_data.count())\n",
    "\n",
    "tasks_train_data = pipeline.fit(tasks_train_df).transform(tasks_train_df)\n",
    "tasks_test_data = pipeline.fit(tasks_test_df).transform(tasks_test_df)\n",
    "\n",
    "print('Task train dataset count:', tasks_train_data.count())\n",
    "print('Task test dataset count:', tasks_test_data.count())\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(labelCol=\"event_success\")\n",
    "random_forest = RandomForestClassifier(labelCol='event_success')\n",
    "gradient_boosting = GBTClassifier(labelCol='event_success')\n",
    "logistic_regression = LogisticRegression(labelCol='event_success')\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\")\n",
    "roc_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"event_success\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T21:29:25.034443300Z",
     "start_time": "2023-06-25T21:29:12.944397Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Jobs Failure Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dt_model_jobs = decision_tree.fit(jobs_train_data)\n",
    "dt_prediction_jobs = dt_model_jobs.transform(jobs_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T18:59:58.703571500Z",
     "start_time": "2023-06-25T18:59:55.335714900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation\n",
      "Accuracy: 0.8015227536993677\n",
      "Recall: 0.7287427034609204\n",
      "F1 score: 0.8024157329760173\n",
      "ROC curve: 0.8147425140029069\n",
      "\n",
      "Feature Importance\n",
      "Feature 'scheduling_class_encoded': 0.17\n",
      "Feature 'priority': 0.22\n",
      "Feature 'cpus': 0.18\n",
      "Feature 'memory': 0.38\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('Model Evaluation')\n",
    "print('Accuracy:', evaluator.evaluate(dt_prediction_jobs, {evaluator.metricName: 'accuracy'}))\n",
    "print('Recall:', evaluator.evaluate(dt_prediction_jobs, {evaluator.metricName: 'recallByLabel'}))\n",
    "print('F1 score:', evaluator.evaluate(dt_prediction_jobs, {evaluator.metricName: 'f1'}))\n",
    "print('ROC curve:', roc_evaluator.evaluate(dt_prediction_jobs, {evaluator.metricName: \"areaUnderROC\"}))\n",
    "\n",
    "# Evaluate feature importance\n",
    "print('\\nFeature Importance')\n",
    "feature_importance = dt_model_jobs.featureImportances.toArray()\n",
    "\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f'Feature \\'{column}\\': {feature_importance[i]:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T18:59:59.830158Z",
     "start_time": "2023-06-25T18:59:58.705571Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "rf_model_jobs = random_forest.fit(jobs_train_data)\n",
    "rf_prediction_jobs = rf_model_jobs.transform(jobs_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T20:47:46.829461Z",
     "start_time": "2023-06-25T20:47:43.882181200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation\n",
      "Accuracy: 0.8139819372103024\n",
      "Recall: 0.7780637180457148\n",
      "F1 score: 0.8150798327374832\n",
      "ROC curve: 0.8205061185804742\n",
      "\n",
      "Feature Importance\n",
      "Feature 'scheduling_class_encoded': 0.16\n",
      "Feature 'priority': 0.09\n",
      "Feature 'cpus': 0.20\n",
      "Feature 'memory': 0.22\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('Model Evaluation')\n",
    "print('Accuracy:', evaluator.evaluate(rf_prediction_jobs, {evaluator.metricName: 'accuracy'}))\n",
    "print('Recall:', evaluator.evaluate(rf_prediction_jobs, {evaluator.metricName: 'recallByLabel'}))\n",
    "print('F1 score:', evaluator.evaluate(rf_prediction_jobs, {evaluator.metricName: 'f1'}))\n",
    "print('ROC curve:', roc_evaluator.evaluate(rf_prediction_jobs, {evaluator.metricName: \"areaUnderROC\"}))\n",
    "\n",
    "# Evaluate feature importance\n",
    "print('\\nFeature Importance')\n",
    "feature_importance = rf_model_jobs.featureImportances.toArray()\n",
    "\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f'Feature \\'{column}\\': {feature_importance[i]:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T20:47:48.224070800Z",
     "start_time": "2023-06-25T20:47:46.829461Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "gb_model_jobs = gradient_boosting.fit(jobs_train_data)\n",
    "gb_prediction_jobs = gb_model_jobs.transform(jobs_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T19:00:20.531047100Z",
     "start_time": "2023-06-25T19:00:03.599986300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation\n",
      "Accuracy: 0.8397158375941766\n",
      "Recall: 0.7645502791599247\n",
      "F1 score: 0.8404732798466041\n",
      "ROC curve: 0.8533689013434725\n",
      "\n",
      "Feature Importance\n",
      "Feature 'scheduling_class_encoded': 0.09\n",
      "Feature 'priority': 0.14\n",
      "Feature 'cpus': 0.07\n",
      "Feature 'memory': 0.44\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('Model Evaluation')\n",
    "print('Accuracy:', evaluator.evaluate(gb_prediction_jobs, {evaluator.metricName: 'accuracy'}))\n",
    "print('Recall:', evaluator.evaluate(gb_prediction_jobs, {evaluator.metricName: 'recallByLabel'}))\n",
    "print('F1 score:', evaluator.evaluate(gb_prediction_jobs, {evaluator.metricName: 'f1'}))\n",
    "print('ROC curve:', roc_evaluator.evaluate(gb_prediction_jobs, {evaluator.metricName: \"areaUnderROC\"}))\n",
    "\n",
    "# Evaluate feature importance\n",
    "print('\\nFeature Importance')\n",
    "feature_importance = gb_model_jobs.featureImportances.toArray()\n",
    "\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f'Feature \\'{column}\\': {feature_importance[i]:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T19:00:21.595521Z",
     "start_time": "2023-06-25T19:00:20.532046200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "lr_model_jobs = logistic_regression.fit(jobs_train_data)\n",
    "lr_prediction_jobs = lr_model_jobs.transform(jobs_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T21:29:30.019578800Z",
     "start_time": "2023-06-25T21:29:25.034443300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation\n",
      "Accuracy: 0.750446791226645\n",
      "Recall: 0.6766825529188918\n",
      "F1 score: 0.751379808707238\n",
      "ROC curve: 0.7638453193426163\n",
      "\n",
      "Feature Importance\n",
      "Feature 'scheduling_class_encoded': 0.29\n",
      "Feature 'priority': 0.13\n",
      "Feature 'cpus': 0.59\n",
      "Feature 'memory': 0.00\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('Model Evaluation')\n",
    "print('Accuracy:', evaluator.evaluate(lr_prediction_jobs, {evaluator.metricName: 'accuracy'}))\n",
    "print('Recall:', evaluator.evaluate(lr_prediction_jobs, {evaluator.metricName: 'recallByLabel'}))\n",
    "print('F1 score:', evaluator.evaluate(lr_prediction_jobs, {evaluator.metricName: 'f1'}))\n",
    "print('ROC curve:', roc_evaluator.evaluate(lr_prediction_jobs, {evaluator.metricName: \"areaUnderROC\"}))\n",
    "\n",
    "# Evaluate feature importance\n",
    "print('\\nFeature Importance')\n",
    "coefficients = lr_model_jobs.coefficients.toArray()[:-2] # remove the additional 2 coefficients\n",
    "\n",
    "# The coefficients are given as logs, so the exponential must be computed, and the values normalized\n",
    "odds_ratios = np.exp(coefficients)\n",
    "normalized_odds = odds_ratios / np.sum(odds_ratios)\n",
    "\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f'Feature \\'{column}\\': {normalized_odds[i]:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T22:01:17.931485300Z",
     "start_time": "2023-06-25T22:01:16.834775Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tasks Failure Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dt_model_tasks = decision_tree.fit(tasks_train_data)\n",
    "dt_prediction_tasks = dt_model_tasks.transform(tasks_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T20:12:27.215012Z",
     "start_time": "2023-06-25T20:11:02.577343800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "dt_model_tasks.save('./task_models_TML/decision_tree')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T19:01:45.168331400Z",
     "start_time": "2023-06-25T19:01:44.574383200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation\n",
      "Accuracy: 0.9879837879354493\n",
      "Recall: 0.9880643422534124\n",
      "F1 score: 0.9885088142283688\n",
      "ROC curve: 0.9872863757309096\n",
      "\n",
      "Feature Importance\n",
      "Feature 'scheduling_class_encoded': 0.04\n",
      "Feature 'priority': 0.35\n",
      "Feature 'cpus': 0.00\n",
      "Feature 'memory': 0.49\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('Model Evaluation')\n",
    "print('Accuracy:', evaluator.evaluate(dt_prediction_tasks, {evaluator.metricName: 'accuracy'}))\n",
    "print('Recall:', evaluator.evaluate(dt_prediction_tasks, {evaluator.metricName: 'recallByLabel'}))\n",
    "print('F1 score:', evaluator.evaluate(dt_prediction_tasks, {evaluator.metricName: 'f1'}))\n",
    "print('ROC curve:', roc_evaluator.evaluate(dt_prediction_tasks, {evaluator.metricName: \"areaUnderROC\"}))\n",
    "\n",
    "# Evaluate feature importance\n",
    "print('\\nFeature Importance')\n",
    "feature_importance = dt_model_tasks.featureImportances.toArray()\n",
    "\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f'Feature \\'{column}\\': {feature_importance[i]:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T19:07:57.444057900Z",
     "start_time": "2023-06-25T19:01:45.168331400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree cross validation result:  0.9932381227693627\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# TODO: explore with other parameters too\n",
    "dt_param_grid = ParamGridBuilder().addGrid(dt_model_tasks.maxDepth, [5, 10, 15]).addGrid(dt_model_tasks.maxBins, [64, 128]).build()\n",
    "\n",
    "dt_cv_evaluator = MulticlassClassificationEvaluator(labelCol=\"event_success\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "dt_cv = CrossValidator(estimator=decision_tree, estimatorParamMaps=dt_param_grid, evaluator=dt_cv_evaluator)\n",
    "\n",
    "dt_cv_model = dt_cv.fit(tasks_train_data)\n",
    "dt_cv_predictions = dt_cv_model.transform(tasks_test_data)\n",
    "\n",
    "dt_cv_auc = evaluator.evaluate(dt_cv_predictions)\n",
    "print(\"Decision Tree cross validation result: \", dt_cv_auc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T20:45:41.199098Z",
     "start_time": "2023-06-25T20:12:27.216012200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "rf_model_tasks = random_forest.fit(tasks_train_data)\n",
    "rf_prediction_tasks = rf_model_tasks.transform(tasks_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T19:10:57.496849300Z",
     "start_time": "2023-06-25T19:07:57.444057900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "rf_model_tasks.save('./task_models_TML/random_forest')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T19:10:58.232705700Z",
     "start_time": "2023-06-25T19:10:57.496849300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation\n",
      "Accuracy: 0.9868253845934012\n",
      "Recall: 0.9866989750868808\n",
      "F1 score: 0.98746995436015\n",
      "ROC curve: 0.9879197956050814\n",
      "\n",
      "Feature Importance\n",
      "Feature 'scheduling_class_encoded': 0.17\n",
      "Feature 'priority': 0.22\n",
      "Feature 'cpus': 0.01\n",
      "Feature 'memory': 0.38\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('Model Evaluation')\n",
    "print('Accuracy:', evaluator.evaluate(rf_prediction_tasks, {evaluator.metricName: 'accuracy'}))\n",
    "print('Recall:', evaluator.evaluate(rf_prediction_tasks, {evaluator.metricName: 'recallByLabel'}))\n",
    "print('F1 score:', evaluator.evaluate(rf_prediction_tasks, {evaluator.metricName: 'f1'}))\n",
    "print('ROC curve:', roc_evaluator.evaluate(rf_prediction_tasks, {evaluator.metricName: \"areaUnderROC\"}))\n",
    "\n",
    "# Evaluate feature importance\n",
    "print('\\nFeature Importance')\n",
    "feature_importance = rf_model_tasks.featureImportances.toArray()\n",
    "\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f'Feature \\'{column}\\': {feature_importance[i]:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T19:22:47.770148400Z",
     "start_time": "2023-06-25T19:10:58.232705700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "gb_model_tasks = gradient_boosting.fit(tasks_train_data)\n",
    "gb_prediction_tasks = gb_model_tasks.transform(tasks_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T19:41:24.433756200Z",
     "start_time": "2023-06-25T19:22:47.770148400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "gb_model_tasks.save('./task_models_TML/gradient_boosting')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T19:41:25.062329100Z",
     "start_time": "2023-06-25T19:41:24.433756200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation\n",
      "Accuracy: 0.9869224955183636\n",
      "Recall: 0.9865438367847023\n",
      "F1 score: 0.9875807085190534\n",
      "ROC curve: 0.9902007955386307\n",
      "\n",
      "Feature Importance\n",
      "Feature 'scheduling_class_encoded': 0.03\n",
      "Feature 'priority': 0.26\n",
      "Feature 'cpus': 0.00\n",
      "Feature 'memory': 0.39\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('Model Evaluation')\n",
    "print('Accuracy:', evaluator.evaluate(gb_prediction_tasks, {evaluator.metricName: 'accuracy'}))\n",
    "print('Recall:', evaluator.evaluate(gb_prediction_tasks, {evaluator.metricName: 'recallByLabel'}))\n",
    "print('F1 score:', evaluator.evaluate(gb_prediction_tasks, {evaluator.metricName: 'f1'}))\n",
    "print('ROC curve:', roc_evaluator.evaluate(gb_prediction_tasks, {evaluator.metricName: \"areaUnderROC\"}))\n",
    "\n",
    "# Evaluate feature importance\n",
    "print('\\nFeature Importance')\n",
    "feature_importance = gb_model_tasks.featureImportances.toArray()\n",
    "\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f'Feature \\'{column}\\': {feature_importance[i]:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T19:53:51.924735700Z",
     "start_time": "2023-06-25T19:41:25.062329100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "lr_model_tasks = logistic_regression.fit(tasks_train_data)\n",
    "lr_prediction_tasks = lr_model_tasks.transform(tasks_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T21:36:24.144484100Z",
     "start_time": "2023-06-25T21:30:51.979848400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "lr_model_tasks.save('./task_models_TML/logistic_regression')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T19:58:11.354225100Z",
     "start_time": "2023-06-25T19:58:11.229250200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation\n",
      "Accuracy: 0.9393074622178677\n",
      "Recall: 0.9375199222077988\n",
      "F1 score: 0.9492245262607429\n",
      "ROC curve: 0.9547833826979623\n",
      "\n",
      "Feature Importance\n",
      "Feature 'scheduling_class_encoded': 0.48\n",
      "Feature 'priority': 0.00\n",
      "Feature 'cpus': 0.00\n",
      "Feature 'memory': 0.52\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('Model Evaluation')\n",
    "print('Accuracy:', evaluator.evaluate(lr_prediction_tasks, {evaluator.metricName: 'accuracy'}))\n",
    "print('Recall:', evaluator.evaluate(lr_prediction_tasks, {evaluator.metricName: 'recallByLabel'}))\n",
    "print('F1 score:', evaluator.evaluate(lr_prediction_tasks, {evaluator.metricName: 'f1'}))\n",
    "print('ROC curve:', roc_evaluator.evaluate(lr_prediction_tasks, {evaluator.metricName: \"areaUnderROC\"}))\n",
    "\n",
    "# Evaluate feature importance\n",
    "print('\\nFeature Importance')\n",
    "coefficients = lr_model_tasks.coefficients.toArray()[:-2] # remove the additional 2 coefficients\n",
    "\n",
    "# The coefficients are given as logs, so the exponential must be computed, and the values normalized\n",
    "odds_ratios = np.exp(coefficients)\n",
    "normalized_odds = odds_ratios / np.sum(odds_ratios)\n",
    "\n",
    "for i, column in enumerate(assembler.getInputCols()):\n",
    "    print(f'Feature \\'{column}\\': {normalized_odds[i]:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T22:19:49.567045700Z",
     "start_time": "2023-06-25T22:06:10.776183600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
